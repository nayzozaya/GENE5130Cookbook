---
title: "Bioinformatics in R WGCNA"
author: "J. Cesar Ignacio Espinoza - Cesar   "
date: "Week 05: April 21th and 23rd 2025"
output: 
  html_document: 
    highlight: espresso
    theme: cerulean
editor_options: 
  markdown: 
    wrap: 72
---

### This class will incorporate a bit of ML.

We will be performing a WGNCA, before proceeding test yourself and make
sure you understand what weighted. Gene_network and correlation mean?

## The dataset.

we will be working with the dataset " Systems biological assessment of
immunity to severe and mild COVID-19 infections"

RNAseq analysis of PBMCs in a group of 17 COVID-19 subjects and 17
healthy controls "

```{r setup}
    ### Edit this line so your notebook renders properly
    knitr::opts_knit$set(root.dir = normalizePath("~/Desktop/Bioinformatics in R")) 
```

We will be using the package called WGCNA, if you do not have it
install, please run this cell, once it is installed comment it!

```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("WGCNA")
```

We now load the libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE, results="hide"}
# We first need to import the important libnrary for today's class, dplyr
library(WGCNA)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
```

Load the data (Counts table and metadata from canvas site)

```{r}
### Run this chunk to import the counts table and metadata into your evironment.
counts <- read.csv('GSE152418RawCounts.csv', header = TRUE, row.names = 1)
metadata <- read.csv('GSE152418Metadata.csv', header = TRUE, row.names = 1)

```

### QC:

Here we wanna explore to see if the dataset that we have is good for
analysis We are going to use a function called goodSamplesGenes(). Use
the cell below to display the help page of this function, figure out if
you can run it, look at the vignette and identify what this function is
doing.

```{r}
gs <- goodSamplesGenes(counts)

#prints the help for the function
```

```{r}
### It look at the boolean list, and use it to subset your dataset
transpose <- t(counts)
gsg <- goodSamplesGenes(transpose)
subset <- transpose[gsg$goodSamples, ]
datExpr <- datExpr[gsg$goodSamples, gsg$goodGenes]
```
```{r}
### It look at the boolean list, and use it to subset your dataset


```

```{r}
### It look at the boolean list, and use it to subset your dataset
gsg <- goodSamplesGenes(t(counts))
gsg$goodGenes

```


```{r}
### It look at the boolean list, and use it to subset your dataset
good_counts <- counts[gsg$goodGenes,]

```

Subset your data so only the genes that passed the filter are kept

```{r}
#base r
library(dplyr)



### dplyr

```

#### Quick lecture 5 mins

#Sidequest 20 mins:

```{r}
# Run this cell as it is, it is generatig artificial data 
set.seed(123)
group1 <- matrix(rnorm(40, mean = 0), ncol = 2)
group2 <- matrix(rnorm(40, mean = 2.5), ncol = 2)
group3 <- matrix(rnorm(40, mean = 8), ncol = 2)

#sends to dataframe
data <- rbind(group1, group2, group3)
rownames(data) <- paste0("P", 1:nrow(data))

# Plot 
df <- as.data.frame(data)
colnames(df) <- c("x", "y")
ggplot(df, aes(x, y)) + 
  geom_point() + 
  theme_minimal()
```

Lookup the hclust function and perform clustering the data, try
different distance methods and agglomeration methods.

```{r}
### Try different distances and methods
?hclust
?dist
```

```{r}
### Try different distances and methods
d_euclidean <- dist(df, method = "euclidean")

# Manhattan distance
d_manhattan <- dist(df, method = "manhattan")
```

```{r}
### Try different distances and methods
EucClust <- hclust(d_euclidean)

plot(EucClust)
```
```{r}
d <- dist(data, method = 'canberra')
methods <- c("single", "complete", "average", "ward.D2")

par(mfrow = c(2,2))
for (m in methods) {
  hc <- hclust(d, method = m)
  plot(hc, main = paste("Method:", m))
}
```
How do the shapes of the deprograms differ?

Which method best recovers the intuitive groupings from the 2D plot?

When might you prefer a chaining method like "single" vs. compact (the
algorithm reduces the variance within created cluster) like "ward.D2"?

```{r}
#### Run this cell as it just plots your points based on the create clusters
d <- dist(data, method = 'canberra')
methods <- c("single", "complete", "average", "ward.D2")

par(mfrow = c(2,2))
for (m in methods) {
  hc <- hclust(d, method = m)
  plot(hc, main = paste("Method:", m))
  

}
```

```{r}
### Run our custom fucntion here, try different agglomaeration methods, and distance
```

#Discuss:

How could this apply to real biological data (e.g., gene expression
clustering)?

## Back to our main topic

Perform clustering on our data **HINT!!!** Double check that columns and
rows are as the program expects them!

A good way to detect outliers is to perform hierarchical clustering of
all the samples. If you do that you should be able to see if some data
points are too far from the rest of the samples.

```{r}
#### Perform CLustering, plot it! WHich samples would you remove?
### Int you can use the base R plot function on the object resulting from clustering
cut_and_color <- function(method, k = 3) {
  hc <- hclust(d, method = method)
  clusters <- cutree(hc, k = k)
  df$cluster <- as.factor(clusters)
  ggplot(df, aes(x, y, color = cluster)) + 
    geom_point(size = 3) +
    labs(title = paste("Clusters with", method, "linkage")) +
    theme_minimal()
}
```

```{r}
### Write your code here
temptree <- hclust(dist(t(good_counts), method = 'euclidean') )
plot(temptree)



```

Outliers are literally that samples taht are far from each other, we can
also look at that by applying dimensionality reduction, one of the most
common techniques is PCA. run the cell below to go to the help page for
PCA

```{r}
?prcomp

```

```{r}
pcomp <- prcomp(t(good_counts))

```

```{r}
#### REMOVE THIS 

```

```{r}

```

```{r}
#Plot the scores of these first two PCS (stored in pca$x)
ggplot(data = pcomp$x, aes(x=PC1, y=PC2)) + geom_point() + geom_text(label = rownames(pcomp$x))
```

# Filter the data to remove bad samples

**HINT** Use DPlyr

```{r}
### TO BE REMOVED. THIS IS DPLYR. MEMORIZE BASIC DATA WRANGL W/ DPLYR
filt <- good_counts %>%
  select(-GSM4614995, -GSM4614993, -GSM4615000)
#good_counts %>% select(-GSM4614987, GSM4614995, GSM4615000)
# can also do this 
```

#Normalization.

The 'easiest' way will be to run DESEq2 and use the normalized counts
object from DESeq2, Look at your past notes and run it below. You have
all you need but you might need to play with the metadata file. HINT :
df[!(row.names(df) %in% row_names_df_to_remove),] \###

```{r}
### TO BE REMOVED. THIS IS DPLYR. MEMORIZE BASIC DATA WRANGL W/ DPLYR
t.meta <-(as.data.frame(t(metadata))) %>% select(-GSM4614995, -GSM4615000, -GSM4614993)
phenotype <- as.data.frame(t(t.meta))

new_pheno <- phenotype %>%
  dplyr::select(-geo_accession, -geographical.location.ch1) %>%
  rename('gender' = 'gender.ch1',
         'days_post_symptom_onset' = 'days_post_symptom_onset.ch1', 
         'disease.state' = 'disease.state.ch1',
         'severity' = 'severity.ch1')
  
new_meta <- (as.data.frame(new_pheno))
#good_counts %>% select(-GSM4614987, GSM4614995, GSM4615000)
# can also do this 
```

```{r}
#REPEAT
dds <- DESeqDataSetFromMatrix(countData = filt, 
                              colData = new_meta,
                              design = ~ disease.state)
## Subset your ddseq object
subset <- dds[(rowSums(counts(dds)) >= 23),]

dds$disease.state <- relevel(dds$disease.state, ref = 'COVID-19')

### Run deseq2

deseq_ob <- DESeq(subset)

#### Save the results to a new object
#res <- results(deseq_ob, alpha = 0.05)
```


```{r}
temptree <- hclust(dist(t(good_counts), method = 'euclidean'))
plot(temptree)
```

```{r}
temp_df <- as.data.frame(t(metadata))
temp_temp <- temp_df %>% select(-GSM4615000, -GSM4614993, -GSM4614995)
new_meta <- as.data.frame(t(temp_temp)) %>% 
  select(-geo_accession, -geographical.location.chl) %>% 
  dplyr:: rename('gender' = 'gender. ch1') %>%
  dplyr:: rename('severity' = 'severity.ch1') %>%
  dplyr:: rename('state' = 'disease state.chl', 'days' = 'days_post_symptom_onset.ch1')
```

```{r}
transposed_metadata <- as.data.frame(t(metadata))
#returns a matrix by default need a dataframe
```

```{r}
transposed_metadata %>%
  dplyr::rename("days_post_symptom_onset.ch1" = "days_post_symptom_onset")
```

```{r}

### WRITE YOUR CODE HERE, ALSO RENAME THE COLUMNS OF METADATA SO IT IS EASIER TO READ, REMOVE 'DOTS' 
phenotype  <- 
 ### remove samples

```

```{r}
new_pheno <-  ### rename headers
```


```{r}
#library(DESeq2)
#dds <- DESeqDataSetFromMatrix(countData = new_pheno, 
#                              colData = new_meta,
#                              design = ~ state)
```
```{r}
relevel(subset$disease.state, ref = 'Healthy')
```

```{r}
dds75 <- dds[(rowSums(counts(dds)) >= 23),]

relevel(dds75$disease.state, ref = 'Healthy')
```

```{r}
dds_norm <- vst(dds75)    ### This applu=ies the normalization without running the whole DESEQ2 function
norm_gene_exp <- t(assay(dds_norm)) ### WGCNA needs the data in a particular shape, make sure this matches it
```

```{r}
deseq_ob <- DESeq(dds75)

res <- results(deseq_ob, alpha = 0.05)
```


Now remove the genes with counts \< 15 in more than 75% of samples
(31\*0.75 \~ 23) This number is coming from the WGCNA recommendations

```{r}
library(EnhancedVolcano)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
BiocManager::install("EnhancedVolcano")

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("org.Hs.eg.db")

```

```{r}
library("org.Hs.eg.db")
sigs.df <-  as.data.frame(res)
sigs.df$symbol <- mapIds(org.Hs.eg.db, keys= rownames(sigs.df), keytype = 'ENSEMBL', colum = "SYMBOL")

```

```{r}
sigs.df

```

### Before proceeding with WGCNA, let's see if you are keeping a cookbook with R, make a vol cano plot, and a heatmap with the DSEQ data you just generated.

```{r}
EnhancedVolcano(sigs.df, x='log2FoldChange', y = 'padj', lab = sigs.df$symbol)
#VOLCANO PLOT

```

```{r}
#remove convalesent values
removed <- new_meta %>%
  filter(severity != "Convalescent")

```

```{r}
shared_samples <- intersect(colnames(filt), rownames(removed))
meta2 <- removed[shared_samples, ]
new_counts <- filt[, shared_samples]
```

```{r}
library(DESeq2)
dds <- DESeqDataSetFromMatrix(countData = new_counts,
                              colData = meta2,
                              design = ~ disease.state)

subset2 <- dds[rowSums(counts(dds)) >= 23, ]

relevel(colData(subset2)$disease.state, ref = 'Healthy')

deseq_ob <- DESeq(subset2)

res2 <- results(deseq_ob, alpha = 0.05)

df.res2 <- as.data.frame(res)

df.res2

```

```{r}

```

```{r}

```





```{r}
### Subset for a heatmap
if (requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)




```

```{r}
### Print your heatmap
diff.df <- as.data.frame(sigs.df)
diff.df <- diff.df %>%
  filter(padj < 0.05)
  
genes_to_test <- rownames(diff.df)

mat <- counts(deseq_ob, normalized = T)[rownames(diff.df),]
mat.z <- t(apply(mat,1, scale))
colnames(mat.z) <- colnames(mat)
Heatmap(mat.z, cluster_rows= T, cluster_columns= T, name = "Z-score", row_labels = diff.df[rownames(mat.z),]$symbol)


```

```{R}
diff.df <- as.data.frame(sigs.df)
diff.df <- diff.df %>%
  filter(padj < 0.05, log2FoldChange > 3.5, baseMean > 100)

mat <- counts(deseq_ob, normalized = T)[rownames(diff.df),]
mat.z <- t(apply(mat,1, scale))
colnames(mat.z) <- colnames(mat)
Heatmap(mat.z, cluster_rows= T, cluster_columns= T, name = "Z-score", row_labels = diff.df[rownames(mat.z),]$symbol)

```



# We can finally start with our WGNCA data analysis

First we pick up a soft threshold modify the power vector below

```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:20), 
                  networkType = "signed", 
                  verbose = 2)
```

You can acess the results with sft\$fitIndices. We are going to pick a
power that gives us the higherst R2 and the lowest mean K.

**HINT plot the data!** First plot Power vs r2

```{r}
ggplot(data = sft$fitIndices, aes(x = Power, y = SFT.R.sq)) + geom_point()
```

Then Plot Power vs mean.k

```{r}
### Follow the example above and plot meanK 
```

After you pick up a threshold we are ready to run our data analysis

While it runs take a look at the vignette
(<https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules>)
to learn about the parameters

```{r}
### Uncoment these cells if you get issues
#temp_cor <-  cor
#cor <- WGCNA::cor

norm_gene_exp[] <- sapply(norm_gene_exp, as.numeric)
### This is the mean meat and potatos function
bwm <- blockwiseModules(norm_gene_exp, 
                 maxBlockSize = 40000,
                 TOMType = "signed",
                 power = 7, 
                 mergeCutHeight = 0.2, 
                 numericLabels = FALSE, 
                 randomSeed = 1234, 
                 verbose = 2)

```

[\#](https://www.rdocumentation.org/packages/WGCNA/versions/1.69/topics/blockwiseModules)explore
the bwm object, how many modules are there? What us the largest module?
What is the smallest?

```{r}
## RUN THIS AS IS, IT WILL PLOT THE COLORS AND DENDROGRAM
## https://www.rdocumentation.org/packages/WGCNA/versions/1.72-5/topics/plotDendroAndColors
mergedColors = labels2colors(bwm$colors)
plotDendroAndColors(
  bwm$dendrograms[[1]],
  mergedColors[bwm$blockGenes[[1]]],
  "Module colors",
  dendroLabels = FALSE,
  hang = 0.03,
  addGuide = TRUE,
  guideHang = 0.05 )

```

# Now we can correlate our findings with phenotype states of patients

Take a look at the phenotype table, we want to correlate these with our
modules (groups of genes), "one-hot encoding", for example"

```         
labels <- c("A", "B", "C")

# One-hot:
A = [1 0 0]
B = [0 1 0]
C = [0 0 1]
```

```{r}
### The easiest way is just to add a new column and subset it at the end, look at the example below, work your way and modify all the relevant traits
traits <- new_pheno %>%
  mutate(disease_state_bin = ifelse(grepl('COVID', disease_state),1,0))

```

```{r}
traits <- new_pheno %>%

```

```{r}
correlations = cor()
```

```{r}
pvalues = corPvalueStudent()
```

```{r}
## Visualiza our moduels as a heatmap
library(ComplexHeatmap)
Heatmap(correlations)
```

Pick up a few modules of interest

```{r}
## Extract the genenames of a module of interest run GSEA on it. 
### HINTS: 
labels2colors(bwm$colors)
names(bwm$colors)

### The easiest ways is to load thes two into  a DF and subset from there, but you can do it anyway.
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```

```{r}
### Run your GSEA here
```
